{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfMrDFmm3muy"
      },
      "source": [
        "# Bangla Named Entity Recognition Using BERT multilingual base model (cased)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9s69mfv3mu8"
      },
      "source": [
        "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "chOaD4go3mu_"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]\n",
        "!pip install accelerate\n",
        "!apt install git-lfs\n",
        "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHl7UYZ7wJ2n"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from datasets import Dataset, DatasetDict, ClassLabel, Sequence, Features, Value\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uGdAmQRuP8_"
      },
      "outputs": [],
      "source": [
        "# Open the data file\n",
        "filepath = '/kaggle/input/bner-6k/data_storage.json'\n",
        "\n",
        "with open(filepath, 'r') as file:\n",
        "    # Load the JSON data from the file\n",
        "    data = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVlWwWTxO3Qz"
      },
      "outputs": [],
      "source": [
        "data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoKs3TsTSUjD"
      },
      "outputs": [],
      "source": [
        "ner_labels = ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n",
        "ner_feature = ClassLabel(names=ner_labels)\n",
        "\n",
        "# Map the raw ner_tag values (like '#1', '#2', etc.) to the actual ner_labels\n",
        "ner_mapping = {\n",
        "    '1': 'O',\n",
        "    '2': 'B-PER',\n",
        "    '3': 'I-PER',\n",
        "    '4': 'B-ORG',\n",
        "    '5': 'I-ORG',\n",
        "    '6': 'B-LOC',\n",
        "    '7': 'I-LOC',\n",
        "    '8': 'B-MISC',\n",
        "    '9': 'I-MISC'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "qeuiDhGESbUU"
      },
      "outputs": [],
      "source": [
        "data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1TZ0JmobN7m"
      },
      "source": [
        "# Function to process tokens and ner_tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_bpPAOPS7x8"
      },
      "outputs": [],
      "source": [
        "\n",
        "def process_data(data):\n",
        "    for entry in data:\n",
        "        # Check if 'tokens' is a string and convert it to a list, otherwise leave it as is\n",
        "        if isinstance(entry['tokens'], str):\n",
        "            entry['tokens'] = eval(entry['tokens'])  # Convert string representation of list to an actual list\n",
        "\n",
        "        # Map 'ner_tag' to actual class labels using the ner_mapping\n",
        "        if isinstance(entry['ner_tag'], str):\n",
        "            entry['ner_tag'] = eval(entry['ner_tag'])  # Convert string representation of list to an actual list\n",
        "\n",
        "        # Map each ner_tag from numeric to the respective class label\n",
        "        entry['ner_tag'] = [tag for tag in entry['ner_tag']]  # Default to 'O' if invalid tag\n",
        "\n",
        "    return data\n",
        "\n",
        "# Process the data\n",
        "data = process_data(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2MEooDjT56U"
      },
      "outputs": [],
      "source": [
        "data_df=pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76JuRoTSDayc"
      },
      "outputs": [],
      "source": [
        "# Retain only necessary columns\n",
        "data_df = data_df[['id', 'tokens', 'ner_tag']].copy()\n",
        "\n",
        "# Convert 'id' to int32\n",
        "data_df['id'] = data_df['id'].astype('int32')\n",
        "\n",
        "# Ensure 'tokens' is a list of strings and clean 'ner_tag' data\n",
        "data_df['tokens'] = data_df['tokens'].apply(lambda x: list(map(str, x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glKhRWbOXWeX"
      },
      "source": [
        "# Convert DataFrames to Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szwBvXzdCQFM"
      },
      "outputs": [],
      "source": [
        "features = Features({\n",
        "    'id': Value('int32'),\n",
        "    'tokens': Sequence(Value('string')),\n",
        "    'ner_tag': Sequence(Value('string'))  # Keep tags as strings\n",
        "})\n",
        "\n",
        "dataset = Dataset.from_pandas(data_df, features=features)\n",
        "\n",
        "# Create DatasetDict\n",
        "raw_datasets = DatasetDict({\n",
        "    'samples': dataset\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQeACRuSI_kd"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizerFast, BertModel\n",
        "\n",
        "# Load the fast tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "# Your existing code to load the model\n",
        "model = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "model_checkpoint=\"bert-base-multilingual-cased\"\n",
        "\n",
        "# Check the tokenizer configuration\n",
        "print(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRTwH_mTpaBZ"
      },
      "outputs": [],
      "source": [
        "tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTnRtWxau0ky"
      },
      "outputs": [],
      "source": [
        "data=raw_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rp4zooZlq4Jy"
      },
      "outputs": [],
      "source": [
        "tokenizer.is_fast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1u4UHRCV5v9"
      },
      "source": [
        "# Align labels with tokens function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hxng56xytyCk"
      },
      "outputs": [],
      "source": [
        "def align_labels_with_tokens(labels, word_ids):\n",
        "    new_labels = []\n",
        "    current_word = None\n",
        "\n",
        "    for word_id in word_ids:\n",
        "        if word_id != current_word:\n",
        "            current_word = word_id\n",
        "            if word_id is None or word_id >= len(labels) or word_id < 0:\n",
        "                label = -100\n",
        "            else:\n",
        "                try:\n",
        "                    label = int(labels[word_id])\n",
        "                except (ValueError, TypeError):\n",
        "                    label = -100  # Default to -100 if conversion fails\n",
        "            new_labels.append(label)\n",
        "\n",
        "        elif word_id is None or word_id >= len(labels) or word_id < 0:\n",
        "            new_labels.append(-100)\n",
        "\n",
        "        else:\n",
        "            try:\n",
        "                label = int(labels[word_id])\n",
        "                if label % 2 == 1:\n",
        "                    label += 1\n",
        "            except (ValueError, TypeError):\n",
        "                label = -100  # Default to -100 if conversion fails\n",
        "\n",
        "            new_labels.append(label)\n",
        "\n",
        "    return new_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4p36h-ioRTx"
      },
      "outputs": [],
      "source": [
        "\n",
        "def tokenize_and_align_labels(examples):\n",
        "  tokenized_inputs = tokenizer(examples['tokens'], truncation=True, is_split_into_words=True)\n",
        "\n",
        "  all_labels = examples['ner_tag']\n",
        "\n",
        "  new_labels = []\n",
        "  for i, labels in enumerate(all_labels):\n",
        "    word_ids = tokenized_inputs.word_ids(i)\n",
        "    new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
        "\n",
        "  tokenized_inputs['labels'] = new_labels\n",
        "\n",
        "  return tokenized_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCFCvAuqCP9-"
      },
      "outputs": [],
      "source": [
        "tokenized_datasets = data.map(tokenize_and_align_labels, batched=True, remove_columns=data['samples'].column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "AR7-ToBkJrvT"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlCCAJi1zFCg"
      },
      "outputs": [],
      "source": [
        "!pip install seqeval\n",
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlOFljafYosn"
      },
      "outputs": [],
      "source": [
        "from seqeval.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "label_names = ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
        "    true_preds = [[label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "                  for prediction, label in zip(predictions, labels)]\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(true_labels, true_preds),\n",
        "        \"precision\": precision_score(true_labels, true_preds),\n",
        "        \"recall\": recall_score(true_labels, true_preds),\n",
        "        \"f1\": f1_score(true_labels, true_preds),\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWM1o77XYunm"
      },
      "outputs": [],
      "source": [
        "len(tokenized_datasets[\"samples\"] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUhs_gF9Yw8e"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments, AutoModelForTokenClassification\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Set seed for reproducibility\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Define number of folds\n",
        "k = 5\n",
        "\n",
        "# Convert HuggingFace Dataset to list of examples for manual slicing\n",
        "dataset_list = tokenized_datasets['samples'].shuffle(seed=seed).to_list()\n",
        "kf = KFold(n_splits=k)\n",
        "\n",
        "# Store evaluation results for each fold\n",
        "results = []\n",
        "fold_metrics = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feJ6Yq6sVncf"
      },
      "source": [
        "# Five-fold cross-validation to check model performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJm2IXylYyBE"
      },
      "outputs": [],
      "source": [
        "for fold, (train_index, val_index) in enumerate(kf.split(dataset_list)):\n",
        "    print(f\"\\n=== Fold {fold + 1}/{k} ===\")\n",
        "\n",
        "    # Split the dataset into train and validation subsets\n",
        "    train_data = [dataset_list[i] for i in train_index]\n",
        "    val_data = [dataset_list[i] for i in val_index]\n",
        "\n",
        "    # Convert lists back to HuggingFace Dataset\n",
        "    from datasets import Dataset\n",
        "    train_dataset = Dataset.from_list(train_data)\n",
        "    val_dataset = Dataset.from_list(val_data)\n",
        "\n",
        "    # Load a fresh model for each fold\n",
        "    model = AutoModelForTokenClassification.from_pretrained(\n",
        "        model_checkpoint,\n",
        "        num_labels=len(label_names),\n",
        "        id2label={i: label for i, label in enumerate(label_names)},\n",
        "        label2id={label: i for i, label in enumerate(label_names)}\n",
        "    )\n",
        "\n",
        "    # Define fold-specific output directory\n",
        "    fold_output_dir = f\"./fold_{fold + 1}_results\"\n",
        "\n",
        "    # Define TrainingArguments\n",
        "    args = TrainingArguments(\n",
        "        output_dir=fold_output_dir,\n",
        "        save_strategy=\"no\",\n",
        "        learning_rate=2e-5,\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=8,\n",
        "        num_train_epochs=3,\n",
        "        weight_decay=0.01,\n",
        "        logging_dir=f\"{fold_output_dir}/logs\",\n",
        "        seed=seed,\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    # Train and evaluate\n",
        "    trainer.train()\n",
        "    eval_result = trainer.evaluate()\n",
        "    results.append(eval_result)\n",
        "    print(f\"Fold {fold + 1} Evaluation:\", eval_result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4TXCP8vY2tN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_results = pd.DataFrame(results)\n",
        "print(\"\\n=== Cross-Validation Average Results ===\")\n",
        "print(df_results.mean())\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
